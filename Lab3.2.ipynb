{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eaba172-ecb2-4bbb-ba8d-627f737fb92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as panda\n",
    "from deeppavlov import configs, build_model\n",
    "import nltk\n",
    "import pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94400daa-e3ee-4dbe-9cfa-b1734e64dab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d729d2-c93a-4e9d-ae0d-e9dbb7900f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = panda.read_csv('C:/Users/maksi/anaconda3/dataset/rusentitweet_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1264a7b2-bf48-4388-9dd1-0e7a45382ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5931677-efa7-4a0b-b7a9-f3c5ea5c79ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3ebf39-baed-4caf-9a09-b33cb4518673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordList = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3721cc-a464-44cf-8ec8-1c3825db79d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ü–æ–º–æ–π–º—É', '—è', '–≤–∫—Ä–∞—à–∏–ª–∞—Å—å', '–≤', '–ß–∏–º–∏–Ω–∞ü§ß', 'https', ':', '//t.co/t2uZTS7NH2']\n"
     ]
    }
   ],
   "source": [
    "print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3251fad-cf47-460f-bdd7-830db53941d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    wordList = nltk.word_tokenize(sentence)\n",
    "    res = list()\n",
    "    for word in wordList:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59367c0a-531e-44a1-b893-023c21415a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ø–æ–º–æ–π–º–∞', '—è', '–≤–∫—Ä–∞—à–∏—Ç—å—Å—è', '–≤', '—á–∏–º–∏–Ω–∞ü§ß', 'https', ':', '//t.co/t2uzts7nh2']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7dfb8-df60-4035-a361-a1f22dbef3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
