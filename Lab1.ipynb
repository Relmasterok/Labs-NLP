{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8ba5a3-96d4-4efc-a6fd-66b24797445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405753bd-0293-4dc8-b675-494296cbc7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 16:19:28.383 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch_crf.tar.gz to C:\\Users\\admin\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz\n",
      "100%|██████████| 1.39G/1.39G [03:37<00:00, 6.38MB/s] \n",
      "2023-10-18 16:23:06.54 INFO in 'deeppavlov.core.data.utils'['utils'] at line 276: Extracting C:\\Users\\admin\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz archive into C:\\Users\\admin\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0893618c87c249729d4ac8551cdba4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)cased/resolve/main/tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\huggingface_hub\\file_download.py:138: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f26d7f78174f2a963d2d04ca82e5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tilingual-cased/resolve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f74561a658047d8b433c81ebc1d91e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ultilingual-cased/resolve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3dc6bdd53f4d57934497fabafa1d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ingual-cased/resolve/main/tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3593ed9ffd4850a7dee226d4bd3698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-10-18 16:28:10.898 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersSequenceTagger on GPU, since no CUDA GPUs are available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "model = build_model('ner_ontonotes_bert_mult', install=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af07f65-8e3f-4de7-9c9a-bd1c65d0b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\aten\\src\\ATen\\native\\TensorCompare.cpp:402.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['Иван', 'живёт', 'в', 'Екатеринбурге', 'и', 'любит', 'Васю', '!']],\n",
       " [['B-PERSON', 'O', 'O', 'B-GPE', 'O', 'O', 'B-PERSON', 'O']]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['Иван живёт в Екатеринбурге и любит Васю!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9430ff-8235-437f-b558-39ab87e59c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
